{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse et intégration des données sur les objets perdus et la fréquentation SNCF, ainsi des données météorologiques de la ville de Paris\n",
    "\n",
    "Ce notebook a comme base les données collectées en format CSV sur l'API SNCF concernant les objets perdus et la fréquentation, ainsi que des données météorologiques de la ville de Paris. Toutes ces données couvrent une période de 2021 à 2023. \n",
    "\n",
    "Nous allons nettoyer, agréger, normaliser ces données, ainsi que réaliser du feature engineering. Enfin, nous créerons une base de données SQLite3 pour rassembler l'ensemble de ces informations en un seul jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dépendances\n",
    "\n",
    "Les dépendances nécessaires à l’exécution du script sont les suivantes :\n",
    "- **Pandas** : Utilisée pour la manipulation et l'analyse des données.\n",
    "- **SQLite3** : Utilisée pour interagir avec les bases de données SQLite.\n",
    "- **OS** : Utilisée pour gérer les chemins de fichiers et répertoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chargement des fichiers csv en noms de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "meteo= pd.read_csv(\"../../csv_modélisé/all_meteo.csv\")\n",
    "objets= pd.read_csv(\"../../csv_modélisé/objets_trouves.csv\")\n",
    "frequentation= pd.read_csv(\"../../csv_modélisé/frequentation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enlever éventuels doublons dans les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo=meteo.drop_duplicates()\n",
    "frequentation=frequentation.drop_duplicates()\n",
    "objets=objets.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mappage de colonne pour avoir le même nom de gare entre les tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequentation['gare'] = frequentation['gare'].replace(\n",
    "    {\"Paris Bercy Bourgogne - Pays d'Auvergne\": \"Paris Bercy\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrondir les valeures des données météo \"cloudcover\" et \"sunhour\" , et conversion type en INT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Arrondir les valeurs des colonnes sélectionnées\n",
    "columns_to_round = ['CLOUDCOVER_AVG_PERCENT', 'SUNHOUR']\n",
    "meteo[columns_to_round] = meteo[columns_to_round].round().astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction du dataframe \"météo\" à partir des colonnes de météo strictmenet nécessaires (principe de minimisation DES données RGPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo = meteo[['DATE'] + columns_to_round]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualisation des colonnes actuelles du dataframe météo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# garder 10 premiers caractéres des lignes date pour un format commun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>gare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Bagagerie: sacs, valises, cartables</td>\n",
       "      <td>Paris Gare de Lyon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>Bagagerie: sacs, valises, cartables</td>\n",
       "      <td>Paris Gare de Lyon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>Bagagerie: sacs, valises, cartables</td>\n",
       "      <td>Paris Gare de Lyon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>Porte-monnaie / portefeuille, argent, titres</td>\n",
       "      <td>Paris Gare de Lyon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>Bagagerie: sacs, valises, cartables</td>\n",
       "      <td>Paris Gare de Lyon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                          type  \\\n",
       "0  2021-01-01           Bagagerie: sacs, valises, cartables   \n",
       "1  2021-01-02           Bagagerie: sacs, valises, cartables   \n",
       "2  2021-01-02           Bagagerie: sacs, valises, cartables   \n",
       "3  2021-01-02  Porte-monnaie / portefeuille, argent, titres   \n",
       "4  2021-01-02           Bagagerie: sacs, valises, cartables   \n",
       "\n",
       "                 gare  \n",
       "0  Paris Gare de Lyon  \n",
       "1  Paris Gare de Lyon  \n",
       "2  Paris Gare de Lyon  \n",
       "3  Paris Gare de Lyon  \n",
       "4  Paris Gare de Lyon  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objets['date'] = objets['date'].str[:10]\n",
    "# va permettre d'avoir un format de date commun à la table météo\n",
    "objets.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mappage des valeures du champ type pour faciliter analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date     type                gare\n",
      "0  2021-01-01  bagages  Paris Gare de Lyon\n",
      "1  2021-01-02  bagages  Paris Gare de Lyon\n",
      "2  2021-01-02  bagages  Paris Gare de Lyon\n",
      "3  2021-01-02      clé  Paris Gare de Lyon\n",
      "4  2021-01-02  bagages  Paris Gare de Lyon\n"
     ]
    }
   ],
   "source": [
    "mappage = {\n",
    "    'Bagagerie: sacs, valises, cartables': 'bagages',\n",
    "    'Porte-monnaie / portefeuille, argent, titres': 'clé',\n",
    "    'Appareils électroniques, informatiques, appareils photo': 'electronique',\n",
    "    'Articles médicaux': 'médical',\n",
    "    'Pièces d identités et papiers personnels': 'papiers',\n",
    "    'Clés, porte-clés, badge magnétique': 'clé',\n",
    "    'Optique': 'optique',\n",
    "    'Divers': 'divers',\n",
    "    'Articles d enfants, de puériculture': 'articles enfants',\n",
    "    'Vêtements, chaussures': 'vetements',\n",
    "    'Vélos, trottinettes, accessoires 2 roues': 'velo/trottinette',\n",
    "    'Instruments de musique': 'article musique',\n",
    "    'Bijoux, montres': 'bijoux/montres',\n",
    "    'Articles de sport, loisirs, camping': 'sport/loisirs',\n",
    "    'Livres, articles de papéterie': 'livres',\n",
    "    'Parapluies': 'parapluies'\n",
    "}\n",
    "\n",
    "# Appliquer le mappage à la colonne 'type'\n",
    "objets['type'] = objets['type'].map(mappage)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame mis à jour pour vérification\n",
    "print(objets.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualisation des différentes valeures du champ \"type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs uniques dans la colonne 'type' :\n",
      "['bagages' 'clé' 'electronique' 'médical' 'papiers' 'optique' 'divers'\n",
      " 'articles enfants' 'vetements' 'velo/trottinette' 'article musique'\n",
      " 'bijoux/montres' 'sport/loisirs' 'livres' 'parapluies']\n"
     ]
    }
   ],
   "source": [
    "valeurs_uniques = objets['type'].unique()\n",
    "\n",
    "# Afficher les valeurs uniques\n",
    "print(\"Valeurs uniques dans la colonne 'type' :\")\n",
    "print(valeurs_uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# entregistrement partiel des résultats en format csv pour éviter d'importer à nouveau toutes les données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.to_csv('../../csv_modélisé/all_meteo.csv', index=False)\n",
    "objets.to_csv('../../csv_modélisé/objets_trouves_bis.csv', index=False)\n",
    "frequentation.to_csv('../../csv_modélisé/frequentation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# création de bdd sqlite \"bdd_pondere.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de données créée dans : /home/utilisateur/Documents/dernier_bdd/certification_finale_bdd_E1/lancement_scripts_projet/nettoyage_des_donnees/bdd_pondere.db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Obtenir le répertoire du script actuel\n",
    "repertoire_actuel = os.getcwd()\n",
    "\n",
    "# Définir le chemin pour la base de données (dans le répertoire actuel)\n",
    "chemin_bdd = os.path.join(repertoire_actuel, 'bdd_pondere.db')\n",
    "\n",
    "# Connexion à la base de données SQLite\n",
    "connexion = sqlite3.connect(chemin_bdd)\n",
    "curseur = connexion.cursor()\n",
    "\n",
    "# Supprimer les tables existantes si elles existent\n",
    "curseur.execute(\"DROP TABLE IF EXISTS frequentation\")\n",
    "curseur.execute(\"DROP TABLE IF EXISTS lumiere\")\n",
    "curseur.execute(\"DROP TABLE IF EXISTS objets_trouves\")\n",
    "\n",
    "# Créer la table 'frequentation' avec nom_gare comme clé primaire\n",
    "curseur.execute(\"\"\"\n",
    "    CREATE TABLE frequentation(\n",
    "        nom_gare TEXT PRIMARY KEY NOT NULL,\n",
    "        frequent_2021 INTEGER,\n",
    "        frequent_2022 INTEGER,\n",
    "        frequent_2023 INTEGER\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Créer la table 'lumiere'\n",
    "curseur.execute(\"\"\"\n",
    "    CREATE TABLE lumiere(\n",
    "        date DATE NOT NULL PRIMARY KEY,\n",
    "        cloud INTEGER,\n",
    "        sun INTEGER,\n",
    "        annee INTEGER \n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Créer la table 'objets_trouves' avec une clé étrangère pour la gare\n",
    "curseur.execute(\"\"\"\n",
    "    CREATE TABLE objets_trouves(\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        date DATE NOT NULL,\n",
    "        type TEXT,\n",
    "        nom_gare TEXT NOT NULL,\n",
    "        poids_pondere FLOAT, \n",
    "        FOREIGN KEY (date) REFERENCES lumiere(date),\n",
    "        FOREIGN KEY (nom_gare) REFERENCES frequentation(nom_gare)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Fermer la connexion\n",
    "connexion.commit()\n",
    "connexion.close()\n",
    "\n",
    "print(f\"Base de données créée dans : {chemin_bdd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# création de bdd sqlite \"luminosite.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de données créée dans : /home/utilisateur/Documents/dernier_bdd/certification_finale_bdd_E1/lancement_scripts_projet/nettoyage_des_donnees/bdd_luminosite.db\n"
     ]
    }
   ],
   "source": [
    "repertoire_actuel = os.getcwd()\n",
    "\n",
    "# Définir le chemin pour la base de données (dans le répertoire actuel)\n",
    "chemin_bdd = os.path.join(repertoire_actuel, 'bdd_luminosite.db')\n",
    "\n",
    "# Connexion à la base de données SQLite\n",
    "connexion = sqlite3.connect(chemin_bdd)\n",
    "curseur = connexion.cursor()\n",
    "\n",
    "# Supprimer les tables existantes si elles existent\n",
    "curseur.execute(\"DROP TABLE IF EXISTS frequentation\")\n",
    "curseur.execute(\"DROP TABLE IF EXISTS lumiere\")\n",
    "curseur.execute(\"DROP TABLE IF EXISTS objets_trouves\")\n",
    "\n",
    "# Créer la table 'frequentation' avec nom_gare comme clé primaire\n",
    "curseur.execute(\"\"\"\n",
    "    CREATE TABLE frequentation(\n",
    "        nom_gare TEXT PRIMARY KEY NOT NULL,\n",
    "        frequent_2021 INTEGER,\n",
    "        frequent_2022 INTEGER,\n",
    "        frequent_2023 INTEGER\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Créer la table 'lumiere'\n",
    "curseur.execute(\"\"\"\n",
    "    CREATE TABLE lumiere(\n",
    "        date TEXT NOT NULL PRIMARY KEY,\n",
    "        cloud INTEGER,\n",
    "        sun INTEGER,\n",
    "        annee INTEGER \n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Créer la table 'objets_trouves' avec une clé étrangère pour la gare\n",
    "curseur.execute(\"\"\"\n",
    "    CREATE TABLE objets_trouves(\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        date DATE NOT NULL,\n",
    "        type TEXT,\n",
    "        nom_gare TEXT NOT NULL,\n",
    "        poids_pondere FLOAT,\n",
    "        FOREIGN KEY (date) REFERENCES lumiere(date),\n",
    "        FOREIGN KEY (nom_gare) REFERENCES frequentation(nom_gare)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Fermer la connexion\n",
    "connexion.commit()\n",
    "connexion.close()\n",
    "\n",
    "print(f\"Base de données créée dans : {chemin_bdd}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import des données dans base de données sqlite (à partir des différents dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données insérées avec succès dans les deux bases de données.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connexion à la première base de données\n",
    "conn_luminosite = sqlite3.connect('bdd_luminosite.db')\n",
    "curseur_luminosite = conn_luminosite.cursor()\n",
    "\n",
    "# Connexion à la seconde base de données\n",
    "conn_pondere = sqlite3.connect('bdd_pondere.db')\n",
    "curseur_pondere = conn_pondere.cursor()\n",
    "\n",
    "\n",
    "\n",
    "# Créer les tables dans la base de données bdd_pondere.db\n",
    "\n",
    "\n",
    "# Insérer les données dans la table 'lumiere'\n",
    "for index, row in meteo.iterrows():\n",
    "    curseur_luminosite.execute(\"INSERT INTO lumiere (date, cloud, sun) VALUES (?, ?, ?)\", \n",
    "                               (row['DATE'], row['CLOUDCOVER_AVG_PERCENT'], row['SUNHOUR']))\n",
    "    curseur_pondere.execute(\"INSERT INTO lumiere (date, cloud, sun) VALUES (?, ?, ?)\", \n",
    "                            (row['DATE'], row['CLOUDCOVER_AVG_PERCENT'], row['SUNHOUR']))\n",
    "\n",
    "# Insérer les données dans la table 'frequentation'\n",
    "for index, row in frequentation.iterrows():\n",
    "    curseur_luminosite.execute(\"INSERT INTO frequentation (nom_gare, frequent_2021, frequent_2022, frequent_2023) VALUES (?, ?, ?, ?)\", \n",
    "                               (row['gare'], row['frequent_2021'], row['frequent_2022'], row['frequent_2023']))\n",
    "    curseur_pondere.execute(\"INSERT INTO frequentation (nom_gare, frequent_2021, frequent_2022, frequent_2023) VALUES (?, ?, ?, ?)\", \n",
    "                            (row['gare'], row['frequent_2021'], row['frequent_2022'], row['frequent_2023']))\n",
    "\n",
    "# Insérer les données dans la table 'objets_trouves'\n",
    "for index, row in objets.iterrows():\n",
    "    curseur_luminosite.execute(\"INSERT INTO objets_trouves (date, type, nom_gare) VALUES (?, ?, ?)\", \n",
    "                               (row['date'], row['type'], row['gare']))\n",
    "    curseur_pondere.execute(\"INSERT INTO objets_trouves (date, type, nom_gare) VALUES (?, ?, ?)\", \n",
    "                            (row['date'], row['type'], row['gare']))\n",
    "\n",
    "# Valider toutes les transactions en une fois\n",
    "conn_luminosite.commit()\n",
    "conn_pondere.commit()\n",
    "\n",
    "# Fermer les connexions\n",
    "conn_luminosite.close()\n",
    "conn_pondere.close()\n",
    "\n",
    "print(\"Données insérées avec succès dans les deux bases de données.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation de données: création d'un dataframe qui reprend les données de la table objets trouvés, calcul et ajout de la valeur du poids pondéré à ce datafarame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul du champ \"poids pondéré\" \n",
    "(sera un indice de valeur de chaque ligne d'objet trouvé, sur lequel on pourra s'appuyer pour l'analyse)\n",
    "\n",
    "1/. Création de 2 DataFrames à partir des tables `frequentation` et `objets_trouves` de la base de données `bdd_luminosité.db`.\n",
    "\n",
    "  \n",
    "2/. Création d'un champ \"année\" à partir du champ \"date\" pour le DataFrame `df_objets`.\n",
    "\n",
    "\n",
    "3/. Initialisation d'un champ \"poids_pondere\" à `df_objets`.\n",
    "\n",
    "\n",
    "4/. Parcours de toutes les lignes de `df_objets`. À partir de la correspondance des champs \"année\" et \"gare\" avec les valeurs du DataFrame `df_frequentation`, on récupère la valeur de fréquentation pour l'insérer dans le champ \"poids_pondere\" de la même ligne.\n",
    "\n",
    "\n",
    "5/. Vérification du mappage correct avec l'affichage des lignes de `df_objets`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date          type            nom_gare  année  poids_pondere\n",
      "0     2021-01-01       bagages  Paris Gare de Lyon   2021       0.036069\n",
      "1     2021-01-02       bagages  Paris Gare de Lyon   2021       0.036069\n",
      "2     2021-01-02       bagages  Paris Gare de Lyon   2021       0.036069\n",
      "3     2021-01-02           clé  Paris Gare de Lyon   2021       0.036069\n",
      "4     2021-01-02       bagages  Paris Gare de Lyon   2021       0.036069\n",
      "...          ...           ...                 ...    ...            ...\n",
      "46321 2023-12-24       bagages         Paris Bercy   2023       0.659723\n",
      "46322 2023-12-24       bagages         Paris Bercy   2023       0.659723\n",
      "46323 2023-12-25       bagages         Paris Bercy   2023       0.659723\n",
      "46324 2023-12-27           clé         Paris Bercy   2023       0.659723\n",
      "46325 2023-12-31  electronique         Paris Bercy   2023       0.659723\n",
      "\n",
      "[46326 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Obtenir le répertoire du script actuel\n",
    "repertoire_script = os.getcwd()\n",
    "\n",
    "# Définir les chemins pour les bases de données\n",
    "chemin_bdd_source = os.path.join(repertoire_script, 'bdd_luminosite.db')\n",
    "\n",
    "# Connexion à la base de données source\n",
    "conn_source = sqlite3.connect(chemin_bdd_source)\n",
    "\n",
    "\n",
    "df_frequentation = pd.read_sql_query(\"SELECT * FROM frequentation\", conn_source)                                # Charge les données de la table 'frequentation' dans un DataFrame\n",
    "\n",
    "df_objets = pd.read_sql_query(\"SELECT * FROM objets_trouves\", conn_source)                                      # Charge les données de la table 'objets_trouves' dans un DataFrame                         \n",
    "\n",
    "\n",
    "# Fermer la connexion après la lecture\n",
    "conn_source.close()\n",
    "\n",
    "                                                                                                                # Étape 1 : Convertir la colonne 'date' en datetime et ajouter une colonne 'année'\n",
    "df_objets['date'] = pd.to_datetime(df_objets['date'])  # Convertir en datetime\n",
    "df_objets['année'] = df_objets['date'].dt.year  # Extraire l'année\n",
    "\n",
    "                                                                                                                # Étape 2 : Calculer la fréquentation minimale de 2021\n",
    "frequent_min_2021 = df_frequentation['frequent_2021'].min()\n",
    "\n",
    "                                                                                                                # Étape 3 et 4 : Remplir la colonne 'poids_pondere'\n",
    "df_objets['poids_pondere'] = 0.0                                                                                # Initialisation à 0\n",
    "\n",
    "                                                                                                                # Calcule le poids pondéré pour chaque objet trouvé\n",
    "for index, row in df_objets.iterrows():\n",
    "    annee = row['année']                                                                                        # Récupére l'année du df des objets trouvés\n",
    "    nom_gare = row['nom_gare']                                                                                  # Récupére le nom de la gare du df des objets trouvés\n",
    "\n",
    "    \n",
    "    variable_a = df_frequentation.loc[df_frequentation['nom_gare'] == nom_gare, f'frequent_{annee}'].values     # calcul de la fréquentation relative à l'objet trouvé (selon sa gare et année de perte)\n",
    "\n",
    "    if variable_a.size > 0:                                                                                     # Vérifie si la valeur existe\n",
    "        variable_a = variable_a[0]                                                                              # Prendre la première valeur\n",
    "\n",
    "        \n",
    "        df_objets.at[index, 'poids_pondere'] = frequent_min_2021 / variable_a                                   # Calcule le poids pondéré\n",
    "\n",
    "                                                                                                                # Affiche les résultats\n",
    "print(df_objets[['date', 'type', 'nom_gare', 'année', 'poids_pondere']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# insertion des données avec le poids pondéré depuis le dataframe créé à la base de données sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données de la table objets_trouves ont été remplacées avec succès.\n"
     ]
    }
   ],
   "source": [
    "repertoire_actuel = os.getcwd()\n",
    "\n",
    "# Définir le chemin pour la base de données\n",
    "chemin_bdd = os.path.join(repertoire_actuel, 'bdd_pondere.db')\n",
    "\n",
    "# Connexion à la base de données SQLite\n",
    "connexion = sqlite3.connect(chemin_bdd)\n",
    "curseur = connexion.cursor()\n",
    "\n",
    "# Supprimer les anciennes données de la table objets_trouves (facultatif)\n",
    "curseur.execute(\"DELETE FROM objets_trouves\")\n",
    "\n",
    "# Insérer les nouvelles données du DataFrame dans la table objets_trouves\n",
    "for index, row in df_objets.iterrows():\n",
    "    curseur.execute(\"\"\"\n",
    "        INSERT INTO objets_trouves (date, type, nom_gare, poids_pondere)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    \"\"\", (row['date'].strftime('%Y-%m-%d'), row['type'], row['nom_gare'], row['poids_pondere']))\n",
    "\n",
    "# Valider les changements et fermer la connexion\n",
    "connexion.commit()\n",
    "connexion.close()\n",
    "\n",
    "print(\"Les données de la table objets_trouves ont été remplacées avec succès.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visuel de la base donnée sqlite \"bdd_pondere\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premières lignes de la table 'objets_trouves':\n",
      "(46327, '2021-01-01', 'bagages', 'Paris Gare de Lyon', 0.036069450579702)\n",
      "(46328, '2021-01-02', 'bagages', 'Paris Gare de Lyon', 0.036069450579702)\n",
      "(46329, '2021-01-02', 'bagages', 'Paris Gare de Lyon', 0.036069450579702)\n",
      "(46330, '2021-01-02', 'clé', 'Paris Gare de Lyon', 0.036069450579702)\n",
      "(46331, '2021-01-02', 'bagages', 'Paris Gare de Lyon', 0.036069450579702)\n",
      "\n",
      "Types des colonnes de la table 'objets_trouves':\n",
      "Colonne: id, Type: INTEGER\n",
      "Colonne: date, Type: DATE\n",
      "Colonne: type, Type: TEXT\n",
      "Colonne: nom_gare, Type: TEXT\n",
      "Colonne: poids_pondere, Type: FLOAT\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Obtenir le répertoire actuel\n",
    "repertoire_actuel = os.getcwd()\n",
    "\n",
    "# Définir le chemin pour la base de données\n",
    "chemin_bdd = os.path.join(repertoire_actuel, 'bdd_pondere.db')\n",
    "\n",
    "# Connexion à la base de données SQLite\n",
    "connexion = sqlite3.connect(chemin_bdd)\n",
    "curseur = connexion.cursor()\n",
    "\n",
    "# Afficher les premières lignes de la table objets_trouves\n",
    "print(\"Premières lignes de la table 'objets_trouves':\")\n",
    "curseur.execute(\"SELECT * FROM objets_trouves LIMIT 5\")\n",
    "rows = curseur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Afficher les types des colonnes\n",
    "print(\"\\nTypes des colonnes de la table 'objets_trouves':\")\n",
    "curseur.execute(\"PRAGMA table_info(objets_trouves)\")\n",
    "columns = curseur.fetchall()\n",
    "for column in columns:\n",
    "    print(f\"Colonne: {column[1]}, Type: {column[2]}\")\n",
    "\n",
    "# Fermer la connexion\n",
    "connexion.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
